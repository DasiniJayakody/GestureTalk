# GestureTalk âœ‹ğŸ—£ï¸

**GestureTalk** is a real-time hand gesture recognition and voice feedback system built using **Python**, **OpenCV**, **MediaPipe**, and **pyttsx3**.

It identifies specific hand gestures through webcam input, displays the gesture name on screen, and uses offline text-to-speech (TTS) to pronounce it â€” providing a simple and effective form of visual-to-auditory communication.

---

## ğŸ¯ Features

- âœ… Real-time gesture detection using MediaPipe
- âœ… Gesture classification without machine learning (rule-based)
- âœ… Text-to-speech (TTS) output using `pyttsx3`
- âœ… On-screen gesture display
- âœ… Supports gestures like:
  - Open Hand âœ‹
  - Fist âœŠ
  - OK ğŸ‘Œ
  - Thumbs Up ğŸ‘
  - Peace âœŒï¸
  - Rock ğŸ¤˜
  - Stop âœ‹
  - Unknown â“

---

## ğŸŒ Real-World Value

GestureTalk can be used as a foundation for:
- ğŸ”‰ Voice-based accessibility tools
- ğŸ¤Ÿ Real-time sign language interpreters (basic version)
- ğŸ“ Educational tools for learning hand gestures or signs
- ğŸ¤– Human-computer interaction (gesture-to-command)

This project demonstrates how computer vision + voice synthesis can empower **inclusive and assistive technology** for users with hearing or speech impairments.

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites
- Python 3.7 or higher
- Webcam

### ğŸ“¦ Install Dependencies

```bash
pip install opencv-python mediapipe pyttsx3

